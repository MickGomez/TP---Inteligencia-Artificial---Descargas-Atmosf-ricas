{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4cvLmObWLIf-"
      },
      "outputs": [],
      "source": [
        "from IPython.utils import strdispatch\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install mplcursors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNbtBgvxL4qR",
        "outputId": "54022676-841b-4cdf-dea5-f146c0e6cf73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mplcursors in /usr/local/lib/python3.10/dist-packages (0.5.3)\n",
            "Requirement already satisfied: matplotlib!=3.7.1,>=3.1 in /usr/local/lib/python3.10/dist-packages (from mplcursors) (3.9.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.7.1,>=3.1->mplcursors) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.7.1,>=3.1->mplcursors) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.7.1,>=3.1->mplcursors) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.7.1,>=3.1->mplcursors) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.7.1,>=3.1->mplcursors) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.7.1,>=3.1->mplcursors) (24.1)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.7.1,>=3.1->mplcursors) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.7.1,>=3.1->mplcursors) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.7.1,>=3.1->mplcursors) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib!=3.7.1,>=3.1->mplcursors) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%% Import necessary packages\n",
        "from tkinter import YES\n",
        "from matplotlib.axes._axes import _log as matplotlib_axes_logger\n",
        "from pyproj import CRS\n",
        "import pickle\n",
        "#os.environ[\"SHAPE_RESTORE.SHX\"] = \"YES\"\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "import seaborn as sns\n",
        "import mplcursors\n",
        "import pandas as pd\n",
        "\n",
        "import geopandas as gpd\n",
        "import matplotlib.animation as animations\n",
        "from numpy import reshape\n",
        "from numpy.ma.core import std\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# Adjust plot font sizes\n",
        "sns.set(font_scale=1.5)\n",
        "# sns.set_style(\"white\")\n",
        "# os.chdir(os.path.join(et.io.HOME, \"earth-analytics\"))"
      ],
      "metadata": {
        "id": "SANf7jQ9Llf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "ruta_base = '/content/drive/MyDrive/2.TPInteligenciaArtificial/Organizado/merged/'\n",
        "\n",
        "# Ubicaciones\n",
        "ubicaciones = ['Asuncion', 'Central', 'Ñeembucu', 'Concepcion']\n",
        "\n",
        "def convertir_timestamp(df):\n",
        "    métodos = [\n",
        "        lambda x: pd.to_datetime(x, format='%Y-%m-%d %H:%M:%S.%f'),\n",
        "        lambda x: pd.to_datetime(x, format='ISO8601'),\n",
        "        lambda x: pd.to_datetime(x, format='mixed'),\n",
        "        lambda x: pd.to_datetime(x, format='mixed', dayfirst=True)\n",
        "    ]\n",
        "\n",
        "    for método in métodos:\n",
        "        try:\n",
        "            return método(df['timestamp'])\n",
        "        except ValueError:\n",
        "            continue\n",
        "\n",
        "    raise ValueError(\"No se pudo convertir la columna timestamp con ningún método.\")\n",
        "\n",
        "def procesar_ubicacion(ubicacion):\n",
        "    try:\n",
        "        # Leer el archivo CSV unificado\n",
        "        archivo = f'merged_{ubicacion}.csv'\n",
        "        ruta_archivo = os.path.join(ruta_base, archivo)\n",
        "        df = pd.read_csv(ruta_archivo)\n",
        "\n",
        "        # Eliminar columnas latitude y longitude\n",
        "        df = df.drop(columns=['latitude', 'longitude'])\n",
        "\n",
        "        # Convertir la columna 'timestamp' a datetime\n",
        "        df['timestamp'] = convertir_timestamp(df)\n",
        "\n",
        "        # Manejar índices duplicados\n",
        "        df = df.sort_values('timestamp').reset_index(drop=True)\n",
        "\n",
        "        # Crear DataFrames para CG e IG\n",
        "        cg_df = pd.DataFrame(index=df.index, columns=['positive', 'negative'])\n",
        "        ig_df = pd.DataFrame(index=df.index, columns=['positive', 'negative'])\n",
        "\n",
        "        # Llenar los DataFrames\n",
        "        cg_mask = df['type'].isin([0, 40])\n",
        "        ig_mask = df['type'] == 1\n",
        "\n",
        "        cg_df.loc[cg_mask, 'positive'] = df.loc[cg_mask & (df['peakcurrent'] > 0), 'peakcurrent']\n",
        "        cg_df.loc[cg_mask, 'negative'] = df.loc[cg_mask & (df['peakcurrent'] < 0), 'peakcurrent']\n",
        "\n",
        "        ig_df.loc[ig_mask, 'positive'] = df.loc[ig_mask & (df['peakcurrent'] > 0), 'peakcurrent']\n",
        "        ig_df.loc[ig_mask, 'negative'] = df.loc[ig_mask & (df['peakcurrent'] < 0), 'peakcurrent']\n",
        "\n",
        "        # Rellenar NaN con 0\n",
        "        cg_df = cg_df.fillna(0)\n",
        "        ig_df = ig_df.fillna(0)\n",
        "\n",
        "        # Añadir la columna timestamp a los DataFrames resultantes\n",
        "        cg_df['timestamp'] = df['timestamp']\n",
        "        ig_df['timestamp'] = df['timestamp']\n",
        "\n",
        "        # Guardar los nuevos archivos\n",
        "        cg_df.to_csv(os.path.join(ruta_base, f'CG_{ubicacion}_unificado.csv'), index=False)\n",
        "        ig_df.to_csv(os.path.join(ruta_base, f'IG_{ubicacion}_unificado.csv'), index=False)\n",
        "\n",
        "        print(f\"Procesado {ubicacion}\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: No se encontró el archivo para {ubicacion}\")\n",
        "    except ValueError as e:\n",
        "        print(f\"Error al procesar {ubicacion}: {str(e)}\")\n",
        "        # Imprimir las primeras filas problemáticas\n",
        "        print(\"Primeras filas problemáticas:\")\n",
        "        print(df['timestamp'].head())\n",
        "    except Exception as e:\n",
        "        print(f\"Error inesperado al procesar {ubicacion}: {str(e)}\")\n",
        "\n",
        "# Procesar cada ubicación\n",
        "for ubicacion in ubicaciones:\n",
        "    procesar_ubicacion(ubicacion)\n",
        "\n",
        "print(\"Procesamiento completado.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lE_ohQ6LL0jB",
        "outputId": "67cce969-89dd-4d78-9ea3-bf42afe0ed04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Procesado Asuncion\n",
            "Procesado Central\n",
            "Procesado Ñeembucu\n",
            "Procesado Concepcion\n",
            "Procesamiento completado.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['timestamp'].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SaD9eeI0cEZY",
        "outputId": "9ab31a8d-e142-4cce-a2db-9a3446c40b79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    2016-01-01 00:33:35.956890106\n",
              "1    2016-01-01 00:33:36.154273987\n",
              "2    2016-01-01 00:49:14.815330029\n",
              "3    2016-01-01 01:02:11.518081903\n",
              "4    2016-01-01 01:14:21.134871006\n",
              "Name: timestamp, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qCgfSAC7Mhez"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}