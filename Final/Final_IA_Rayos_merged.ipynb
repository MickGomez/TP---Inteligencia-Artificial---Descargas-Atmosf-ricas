{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Para unir los df de cada año en uno solo, manteniendo separadas las 4 ubicaciones: **Asuncion, Central, Ñeembucu, Concepcion**"
      ],
      "metadata": {
        "id": "yF5Q8_EDPEhQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importar las librerias"
      ],
      "metadata": {
        "id": "uU7cR47XPLX-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oWZpdDvxO5Tx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Funcion para unificar 2016 a 2022 exceptuando 2019 ( formato distinto de manejo)"
      ],
      "metadata": {
        "id": "0UIllWYTPuUU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_files(filepath, years, locations):\n",
        "  \"\"\"\n",
        "  Merge archivos anuales a uno solo, por region\n",
        "  \"\"\"\n",
        "  for location in locations:\n",
        "    dfs = []  # List to store dataframes for each year\n",
        "    merged_df = pd.DataFrame()\n",
        "    for year in years:\n",
        "      file_path = os.path.join(filepath,f\"{year}_{location}.csv\")\n",
        "      if os.path.exists(file_path):\n",
        "          print(\"existe algo\")\n",
        "          df = pd.read_csv(file_path, usecols=['timestamp','type', 'latitude', 'longitude', 'peakcurrent'])\n",
        "          dfs.append(df)\n",
        "      if not dfs:\n",
        "        print(f\"No se encontraron archivos para la ubicación {location}\")\n",
        "        continue\n",
        "\n",
        "    # Merge all dataframes in the list\n",
        "    merged_df = pd.concat(dfs, ignore_index=False)\n",
        "    # Save the merged dataframe to a new CSV file\n",
        "    merged_df.to_csv(f\"/content/drive/MyDrive/2.TPInteligenciaArtificial/Organizado/merged/merged_{location}.csv\", index=True)\n",
        "\n",
        "    print (f\"merged file guardado en /content/drive/MyDrive/2.TPInteligenciaArtificial/Organizado/merged/merged_{location}.csv\")"
      ],
      "metadata": {
        "id": "7DkIbIeSPet1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instanciados de codigos y especificaciones de directorios"
      ],
      "metadata": {
        "id": "QIwYk6ZhQrOr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Base path\n",
        "base_path = \"/content/drive/MyDrive/2.TPInteligenciaArtificial/Organizado/Anuales\"\n",
        "#Los anhos a iterar y las regiones\n",
        "years = ['2016_filtrado', '2017_filtrado', '2018_filtrado', '2019_filtrado', '2020_filtrado', '2021_filtrado']\n",
        "locations = ['Asuncion','Central', 'Ñeembucu', 'Concepcion']\n",
        "#parts = [1, 2, 3, 4, 5, 6]\n",
        "# llama a la funcion que unifica por region\n",
        "# Merge files for all years except 2019\n",
        "merge_files(base_path, years, locations)\n",
        "\n",
        " # Merge files for the year 2019\n",
        "#merge_2019_files(base_path, locations, parts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qhPhtgaQk9e",
        "outputId": "eadbaf26-7827-4c96-ab6a-64e3788f9bd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "existe algo\n",
            "existe algo\n",
            "existe algo\n",
            "existe algo\n",
            "existe algo\n",
            "merged file guardado en /content/drive/MyDrive/2.TPInteligenciaArtificial/Organizado/merged/merged_Asuncion.csv\n",
            "existe algo\n",
            "existe algo\n",
            "existe algo\n",
            "existe algo\n",
            "merged file guardado en /content/drive/MyDrive/2.TPInteligenciaArtificial/Organizado/merged/merged_Central.csv\n",
            "existe algo\n",
            "existe algo\n",
            "existe algo\n",
            "existe algo\n",
            "merged file guardado en /content/drive/MyDrive/2.TPInteligenciaArtificial/Organizado/merged/merged_Ñeembucu.csv\n",
            "existe algo\n",
            "existe algo\n",
            "existe algo\n",
            "existe algo\n",
            "merged file guardado en /content/drive/MyDrive/2.TPInteligenciaArtificial/Organizado/merged/merged_Concepcion.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b2fxmJsuHp3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NBj1_C9CHqBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-DyT_Y6oHqJG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}